# ğŸ“Š Customer Churn Prediction

A complete end-to-end **Machine Learning project** to predict customer churn using the **Telco Customer Churn dataset**.
The repository includes preprocessing scripts, training, evaluation, and inference pipeline â€” with saved models and reports.

---

## ğŸ“‚ Project Structure

```
customer-churn-prediction/
â”œâ”€ data/                     # Raw dataset (Telco-Customer-Churn.csv)
â”œâ”€ models/                   # Saved trained models (.pkl)
â”œâ”€ notebooks/                # Jupyter notebooks (EDA & experiments)
â”‚   â”œâ”€ 01_data_cleaning.py
â”‚   â”œâ”€ 02_model_training.py
â”‚   â”œâ”€ 03_model_evaluation.py
â”‚   â””â”€ 04_inference.py
â”œâ”€ reports/                  # Evaluation results and plots
â”‚   â”œâ”€ evaluation_report.csv
â”‚   â”œâ”€ images/
â”‚   â”‚   â””â”€ flowchart.png
â”œâ”€ src/                      # Core source code
â”‚   â”œâ”€ preprocessing.py
â”‚   â”œâ”€ train.py
â”‚   â”œâ”€ evaluate.py
â”‚   â””â”€ predict.py
â”œâ”€ requirements.txt
â””â”€ README.md
```

---

## âš¡ Quick Start

1. **Create a virtual environment and install dependencies**:

```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate

pip install --upgrade pip
pip install -r requirements.txt
```

2. **Place dataset** inside:

```
data/Telco-Customer-Churn.csv
```

3. **Run the pipeline step by step**:

* **Preprocessing**

```bash
python notebooks/01_data_cleaning.py
```

* **Training**

```bash
python notebooks/02_model_training.py
```

* **Evaluation**

```bash
python notebooks/03_model_evaluation.py
```

* **Inference (predictions on new data)**

```bash
python notebooks/04_inference.py
```

---

## ğŸ§‘â€ğŸ¤– Whatâ€™s Inside?

* **Exploratory Data Analysis (EDA)**: Distributions, correlations, churn insights.
* **Preprocessing**: Handling missing values, encoding categorical features, scaling numerical features.
* **Models**: Logistic Regression, Random Forest, XGBoost, Gradient Boosting.
* **Evaluation**: Accuracy, Precision, Recall, F1, ROC-AUC, Confusion Matrix, ROC curves.
* **Model Selection**: Best model automatically chosen from evaluation report.
* **Inference**: Generate churn predictions for new customers.

---

## ğŸ“ˆ Example Results

Confusion Matrix & ROC Curve plots are automatically saved in the `reports/` folder.
Example:

![Confusion Matrix](reports/images/confusion_matrix.png)
![ROC Curve](reports/images/roc_curve.png)

---

## ğŸ”„ Pipeline Flow

The full workflow is illustrated below:

```mermaid
graph TD
    A[Load Dataset] --> B[Preprocessing]
    B --> C[Model Training]
    C --> D[Model Evaluation]
    D --> E[Select Best Model]
    E --> F[Save Model]
    F --> G[Inference on New Data]
```

**Steps:**

1. Load & clean dataset
2. Preprocess features
3. Train models (Logistic Regression, Random Forest, XGBoost, etc.)
4. Evaluate & compare models
5. Save best model
6. Run inference on new customers

---

## ğŸ“ Notes

* Class imbalance is handled with `class_weight='balanced'` and optional SMOTE.
* Reports (`evaluation_report.csv`) summarize all models for comparison.
* The pipeline is modular: you can replace or extend models easily.

---

## ğŸŒ Summary

This repository provides a **complete ML pipeline** to predict customer churn using the Telco dataset.
It covers the full cycle: **data cleaning â†’ preprocessing â†’ model training â†’ evaluation â†’ inference**, with saved models and visual reports.

